{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_Example_Ames_Housing_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titsitits/Python_Data_Science/blob/master/8_Example_Ames_Housing_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfQ-d2onvooo",
        "colab_type": "text"
      },
      "source": [
        "Mickaël Tits\n",
        "CETIC\n",
        "mickael.tits@cetic.be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvc0ah8oge9x",
        "colab_type": "text"
      },
      "source": [
        "# Chapitre 8 - Un exemple concret: estimation du prix d'une maison à Ames (Iowa, USA)\n",
        "\n",
        "Dans ce Chapitre, nous allons analyser un vrai Dataset de biens immobiliers: le \"Ames Housing Dataset\". A partir de ces données, nous allons développer un modèle prédictif permettant d'estimer le prix d'une maison à partir de nombreuses caractéristiques, telles que sa surface, le nombre de pièces, différents indices de qualité, etc.\n",
        "\n",
        "Plus d'informations ici: \n",
        "https://www.kaggle.com/c/home-data-for-ml-course/overview/description\n",
        "\n",
        "http://jse.amstat.org/v19n3/decock.pdf\n",
        "\n",
        "Détails sur les variables du dataset: https://github.com/titsitits/Python_Data_Science/blob/master/Donn%C3%A9es/data_description.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO_L0DC-QxU9",
        "colab_type": "text"
      },
      "source": [
        "## Préparation/exploration du dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rW_gAdoCDOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ames = pd.read_csv(\"https://raw.githubusercontent.com/titsitits/Python_Data_Science/master/Donn%C3%A9es/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_SeXJLmSp2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nrcLRYFj_jN",
        "colab_type": "text"
      },
      "source": [
        "Commençons par explorer brièvement la qualité des données.\n",
        "\n",
        "On a 1460 observations (maisons), et 81 variables dont un Id et le prix de vente (SalePrice). 19 variables contiennent des données invalides ou manquantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi8-lBq2Nd0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Quelques fonctions utiles pour l'exploration\n",
        "\n",
        "#Par soucis de lisibilité, on affichera les series comme des dataframes d'une ligne\n",
        "def display_series(series):  \n",
        "  display(series.to_frame().transpose())\n",
        "  \n",
        "#Corrélation entre deux colonnes\n",
        "def col_corr(df,col1,col2):  \n",
        "  return df[[col1,col2]].corr().values[0,1]\n",
        "\n",
        "#Pour analyser l'effet d'une variable continue sur une autre, on peut extraire deux groupes (chaque côté de la médiane), et afficher un boxplot par groupe\n",
        "def mediangroups_boxplot_comparison(df, group_col, comparison_col):\n",
        "  df[\"above_median\"] = df[group_col] > df[group_col].quantile(0.5)\n",
        "  df.boxplot(comparison_col, by = \"above_median\")\n",
        "  df.pop(\"above_median\")\n",
        "\n",
        "#Pour analyser l'effet d'une variable continue sur une autre, on peut extraire deux groupes (chaque côté de la médiane), et calculer la moyenne par groupe\n",
        "def mediangroups_mean_comparison(df, group_col, comparison_col):  \n",
        "  means = df.groupby(df[group_col] > df[group_col].quantile(0.5))[comparison_col].mean()\n",
        "  means.index = ['Below','Above']\n",
        "  return means\n",
        "\n",
        "#Idem en séparant les groupes avec la moyenne\n",
        "def meangroups_mean_comparison(df, group_col, comparison_col):\n",
        "  means = df.groupby(df[group_col] > df[group_col].mean())[comparison_col].mean()\n",
        "  means.index = ['Below','Above']\n",
        "  return means"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjnQoJAxkKi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(ames.shape)\n",
        "print(list(ames.columns))\n",
        "\n",
        "#Colonnes incomplètes\n",
        "counts = ames.count()\n",
        "incomplete = counts[counts < len(ames)]\n",
        "display_series(incomplete.sort_values())\n",
        "len(incomplete.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uRAS8sdiw39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ames.hist(\"SalePrice\", bins = 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNidzJlk0Ysk",
        "colab_type": "text"
      },
      "source": [
        "### Données manquantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6na2mKJInz9N",
        "colab_type": "text"
      },
      "source": [
        "sur les 19 variables incomplètes, 3 sont des variables numériques (les variables de type \"float64\"), et les autres sont des variables catégorielles (les variables de type \"object\").\n",
        "\n",
        "Après vérification de la description des variables, on remarque que les variables catégorielles contiennent des \"NA\" comme catégories, et qui sont automatiquement interprétées comme des NaN par pandas. \n",
        "\n",
        "Pour les variables catégorielles, nous allons simplement remplacer les NaN par une catégorie \"Nothing\". Nous allons ensuite analyser et corriger chaque variable numérique.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMH9OkrIpRWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pour vérifier le type d'une colonne: .dtypes()\n",
        "display_series(ames.dtypes)\n",
        "#Les variables catégorielles sont du type \"object\"\n",
        "\n",
        "#Vérifions les données incomplètes uniquement:\n",
        "incomplete_types = ames[incomplete.index].dtypes\n",
        "display_series(incomplete_types)\n",
        "\n",
        "#Trois variables de type \"float64\" contiennent des NaN\n",
        "display_series(incomplete_types[incomplete_types == \"float64\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC7ZwVA-XR7s",
        "colab_type": "text"
      },
      "source": [
        "#### Correction de variables catégorielles\n",
        "Pour les variables catégorielles, remplaçons les NaN par la catégorie \"Nothing\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgDXdSDeoitq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_columns = ames.columns[ames.dtypes == 'object']\n",
        "for col in cat_columns:\n",
        "  ames[col] = ames[col].fillna('Nothing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FfB4Ys1XVPF",
        "colab_type": "text"
      },
      "source": [
        "#### Exploration et correction des variables numériques\n",
        "Analysons la qualité de chaque variable: quelle est la proportion de données manquantes ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3xRRb6ep7k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts = ames.count()\n",
        "incomplete = counts[counts < len(ames)]\n",
        "display_series(incomplete.sort_values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KECCDEox5Zt",
        "colab_type": "text"
      },
      "source": [
        "Est-ce que le fait que la variable soit manquante est en soi une information intéressante ? autrement dit, est-ce que ça a une influence sur le prix ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzL2lKa0r7AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mean price for NaNs and for non-NaNs\n",
        "display(ames.groupby(ames.LotFrontage.isna())[\"SalePrice\"].agg(['median','mean']))\n",
        "display(ames.groupby(ames.GarageYrBlt.isna())[\"SalePrice\"].agg(['median','mean']))\n",
        "display(ames.groupby(ames.MasVnrArea.isna())[\"SalePrice\"].agg(['median','mean']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXcg6gWatKZD",
        "colab_type": "text"
      },
      "source": [
        "L'absence de LotFrontage ne semble pas avoir beaucoup d'influence sur le prix. Les deux autres variables ont une influence. GarageYrBlt = NaN signifie probablement qu'il n'y a pas de garage (ce qui diminue la valeur), et MasVnrArea = NaN semble augmenter la valeur en moyenne.\n",
        "\n",
        "Pour une comparaison plus complète, nous pouvons visualiser les distributions des valeurs NaNs et non-NaN pour chacune de ces variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TY52lH6cylg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "fig, axes = plt.subplots(1,3)\n",
        "\n",
        "for ax, feat in zip(axes, ['LotFrontage', 'GarageYrBlt','MasVnrArea']):\n",
        "  ax.violinplot(dataset = [ames[ames[feat].isna()]['SalePrice'].values, ames[ames.notna()]['SalePrice'].values] )\n",
        "  ax.set_xlabel(feat)\n",
        "  ax.set_xticks([1,2])\n",
        "  ax.set_xticklabels(['NaNs','valid'])\n",
        "\n",
        "#Permet d'éviter l'overlap entre les subplots\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8988suQTvwIX",
        "colab_type": "text"
      },
      "source": [
        "##### MasVnrArea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kPorBFzt2EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Analysons la relation entre \"MasVnrArea\" et le prix\n",
        "print(col_corr(ames,\"MasVnrArea\",\"SalePrice\"))\n",
        "display_series(mediangroups_mean_comparison(ames,\"MasVnrArea\",\"SalePrice\"))\n",
        "mediangroups_boxplot_comparison(ames,\"MasVnrArea\",\"SalePrice\")\n",
        "ames.plot.scatter(\"MasVnrArea\",\"SalePrice\")\n",
        "#Il semblerait que l'influence soit positive\n",
        "\n",
        "#Une possibilité pour prendre en compte cette information est de remplacer les NaN la moyenne de la colonne (ce qui minimisera l'influence de la variable pour ces observations particulières), et d'ajouter une colonne \"isnan_MasVnrArea\" pour garder l'information\n",
        "#La relation entre \"MasVnrArea\" et \"SalePrice\" ne devrait pas être trop faussée de cette manière, étant donné que le nombre de NaN est assez faible (81).\n",
        "ames[\"isnan_MasVnrArea\"] = ames.MasVnrArea.isna().astype(int) #.astype(int) permet de rendre la variable numérique. #.astype(str) permettrait d'en faire une variable catégorielle\n",
        "ames[\"MasVnrArea\"] = ames[\"MasVnrArea\"].fillna(ames[\"MasVnrArea\"].median())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a9-9-fqv2h6",
        "colab_type": "text"
      },
      "source": [
        "##### LotFrontage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri_eA_YQxnvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Analysons la relation entre \"LotFrontage\" et le prix\n",
        "print(col_corr(ames,\"LotFrontage\",\"SalePrice\"))\n",
        "display_series(mediangroups_mean_comparison(ames,\"LotFrontage\",\"SalePrice\"))\n",
        "mediangroups_boxplot_comparison(ames,\"LotFrontage\",\"SalePrice\")\n",
        "ames.plot.scatter(\"LotFrontage\",\"SalePrice\", s = 1)\n",
        "\n",
        "#Ajoutons une variable isnan_LotFrontage pour pouvoir utiliser cette information dans notre modèle plus tard:\n",
        "ames[\"isnan_LotFrontage\"] = ames.LotFrontage.isna().astype(int)\n",
        "#Ensuite, étant donné le grand nombre de NaNs (~18%), il est préférable (dans une premier temps) de ne pas utiliser cette variable en remplaçant les NaN par la moyenne\n",
        "#Une autre possibilité serait d'entraîner un modèle de régression pour prédire ces données manquantes à partir des autres variables.\n",
        "out = ames.pop(\"LotFrontage\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xi5TJ6r2V5p",
        "colab_type": "text"
      },
      "source": [
        "On ne peut pas considérer Lotfrontage = NaN comme 0, auquel cas le prix moyen serait plus faible que pour les autres maisons. Il est préférable d'omettre la variable vu la quantité de NaN (plus de 10%). Remplacer NaN par une valeur apporterait des informations erronnées, et omettre les observations réduirait significativement la taille du dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooOgJTxIv5k8",
        "colab_type": "text"
      },
      "source": [
        "##### GarageYrBlt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeIP_RARu4qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Concernant l'année de construction du garage, une valeur nulle n'aurait aucun sens.\n",
        "#On peut vérifier que la NaN correspond simplement à une absence de garage. En effet, leur surface est toujours nulle:\n",
        "display_series(ames[ames.GarageYrBlt.isna()].GarageArea.describe())\n",
        "#L'information sur l'absence de garage est donc déjà présente dans une autre variable. \n",
        "\n",
        "ames.corrwith(ames[\"GarageYrBlt\"]).sort_values(ascending = False).plot.bar(figsize = (10,4))\n",
        "#On remarque aussi que l'année de construction du garage est logiquement corrélée avec l'année de construction du bien.\n",
        "#Pour remplir les quelques NaN, on peut éventuellement \"simuler\" une date de construction du garage avec l'année de construction.\n",
        "ames[\"GarageYrBlt\"] = ames[\"GarageYrBlt\"].fillna(ames[\"YearBuilt\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgsIPuREtEwY",
        "colab_type": "text"
      },
      "source": [
        "#### Suppression des variables inutiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ECUyuFItBQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = ames.pop(\"Id\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TSUZHdqnx7U",
        "colab_type": "text"
      },
      "source": [
        "#### Tout en une fonction\n",
        "Il est intéressant de redéfinir le pipeline de correction avec une fonction, pour pouvoir le réappliquer plus tard sur de nouvelles données (le set de test par exemple)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIq7Ie0iM21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_df(df):\n",
        "  #Fill categorical columns\n",
        "  cat_columns = df.columns[df.dtypes == 'object']\n",
        "  for col in cat_columns:\n",
        "    df[col] = df[col].fillna('Nothing')\n",
        "  \n",
        "  #Clean MasVnrArea\n",
        "  df[\"isnan_MasVnrArea\"] = df.MasVnrArea.isna().astype(int)\n",
        "  df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(df[\"MasVnrArea\"].mean())\n",
        "  \n",
        "  #Clean LotFrontage\n",
        "  df[\"isnan_LotFrontage\"] = df.LotFrontage.isna().astype(int)\n",
        "  df = df.drop(\"LotFrontage\", axis=1)\n",
        "  \n",
        "  #Clean GarageYrBlt\n",
        "  df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].fillna(df[\"YearBuilt\"])\n",
        "  \n",
        "  #Suppression des variables inutiles\n",
        "  out = df.pop(\"Id\")\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOQxM9NltjAW",
        "colab_type": "text"
      },
      "source": [
        "## Sélection de variables prédictives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m308qsX1pXLP",
        "colab_type": "text"
      },
      "source": [
        "### Analyse de corrélation (variables continues)\n",
        "\n",
        "Remarque: les méthodes pandas.DataFrame.corr() et .corrwith() omettent automatiquement les variables non-numériques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdC4Ay36fqTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#corrélations des variables avec le prix\n",
        "corr_with_price = ames.corrwith(ames[\"SalePrice\"])\n",
        "\n",
        "#On trie les variables selon la valeur absolue de leur corrélation avec le prix\n",
        "best_features = corr_with_price.abs().sort_values(ascending=False)\n",
        "\n",
        "# On ne évidemment peut utiliser le label comme variable prédictive\n",
        "best_features.pop(\"SalePrice\")\n",
        "\n",
        "best_features.plot.bar(figsize=(10,4))\n",
        "\n",
        "best_features = best_features.index.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWA7fcF4rHOH",
        "colab_type": "text"
      },
      "source": [
        "### Analyse basique d'effet des variables continues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIiC_LlqrENl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Analyse de l'effet\n",
        "continuous_col = ames.columns[(ames.dtypes == 'int64') | (ames.dtypes == 'float64')]\n",
        "\n",
        "delta_mean = []\n",
        "\n",
        "for col in list(continuous_col):  \n",
        "  means = meangroups_mean_comparison(ames, col, \"SalePrice\")\n",
        "  delta_mean.append( means[1] - means[0] )\n",
        "\n",
        "best_features_effects = pd.Series(delta_mean, continuous_col).abs().sort_values(ascending = False)\n",
        "best_features_effects = best_features_effects.drop(\"SalePrice\")\n",
        "best_features_effects.plot.bar(figsize=(10,4))\n",
        "\n",
        "best_features_effects = best_features_effects.index.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi5_I8Z9yMfD",
        "colab_type": "text"
      },
      "source": [
        "Les résultats sont assez similaires. En réalité, les différences principales se trouvent pour les variables dont la distribution est fortement asymmétrique (e.g.: PoolArea est la plupart du temps 0, tout comme isnan_MasVnrArea)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fl5jS12zcMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(1,4,figsize = (15,3))\n",
        "ames.boxplot(\"OverallQual\", ax = axes[0])\n",
        "ames.boxplot(\"GrLivArea\", ax = axes[1])\n",
        "ames.boxplot(\"PoolArea\", ax = axes[2])\n",
        "ames.boxplot(\"isnan_MasVnrArea\", ax = axes[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GieK4cCJQecG",
        "colab_type": "text"
      },
      "source": [
        "## Préparation des sets d'entraînement et de validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZcr_oCYSmm9",
        "colab_type": "text"
      },
      "source": [
        "### Sélection des variables prédictives (features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjOypw1hSXD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prenons les cinq meilleures variables prédictives (en sa basant sur leur corrélation avec le prix, ou le delta de la moyenne)\n",
        "featurelist = best_features[:5]\n",
        "#featurelist = best_features_effects[:5]\n",
        "\n",
        "X = ames[featurelist]\n",
        "y = ames[\"SalePrice\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCqFx1_6Sq92",
        "colab_type": "text"
      },
      "source": [
        "### Séparation des données d'entraînement et de validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDKVXwL9m5l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "ids = ames.index\n",
        "\n",
        "trainids, valids = train_test_split(ids, test_size = 0.4, random_state = 1)\n",
        "\n",
        "#Pour avoir à chaque fois des ids différents, il suffit de ne pas fixer l'état pseudo alétoire \"random_state\":\n",
        "#trainids, valids = train_test_split(ids, test_size = 0.4)\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "\n",
        "#Remarque: ce code est équivalent, mais le but ici est de garder les mêmes ids pour comparer plusieurs modèles (ou pour calculer la moyenne des prédictions, voir fin du notebook)\n",
        "#Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size = 0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laD_Mgz0S4d1",
        "colab_type": "text"
      },
      "source": [
        "## Régression linéaire"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pij4mZ5l32w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "price_predictor = LinearRegression()\n",
        "price_predictor.fit(Xtrain, ytrain)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4wMp6XSmJFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE\n",
        "\n",
        "\n",
        "print(\"R2 Scores (train, val):\", price_predictor.score(Xtrain, ytrain), price_predictor.score(Xval, yval))\n",
        "\n",
        "y_pred = price_predictor.predict(Xval)\n",
        "\n",
        "print(\"biais:\", np.mean(y_pred - yval.values) ) #si il est négatif: sous-évaluation (en moyenne), si il est positif: sur-évaluation\n",
        "print(\"MAE:\", MAE(yval.values, y_pred) )\n",
        "print(\"RMSE:\", np.sqrt(MSE(yval.values, y_pred)) )\n",
        "\n",
        "#Tester en gardant ou en retirant les outliers; tester avec différentes ensembles de variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJP043J4-Y0-",
        "colab_type": "text"
      },
      "source": [
        "Remarque: les résultats seront un peu différents chaque fois qu'on relancera le code, étant donné la sélection aléatoire des sets d'entraînement et de validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oTHcBp-Svi3",
        "colab_type": "text"
      },
      "source": [
        "## Comparaison pour différents nombres de variables prédictives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Rd7RnFo57A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "maes = pd.DataFrame(columns = ['train','val'])\n",
        "\n",
        "for n in range(1,len(best_features)):\n",
        "\n",
        "  #Choix des variables\n",
        "  featurelist = best_features[:n]\n",
        "  #featurelist = best_features_effects[:n]\n",
        "  \n",
        "  #Commencer par les plus mauvaises\n",
        "  #featurelist = best_features[::-1][:n]\n",
        "  #featurelist = best_features_effects[::-1][:n]\n",
        "\n",
        "  X = ames[featurelist]\n",
        "  y = ames[\"SalePrice\"]  \n",
        "  \n",
        "  Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "  #scaler = StandardScaler()\n",
        "  #Xtrain = scaler.fit_transform(Xtrain)\n",
        "  #Xval = scaler.transform(Xval)\n",
        "  price_predictor.fit(Xtrain, ytrain)\n",
        "  trainpred = price_predictor.predict(Xtrain)\n",
        "  valpred = price_predictor.predict(Xval)\n",
        "  \n",
        "  maes.loc[n] = MAE(ytrain, trainpred), MAE(yval, valpred)\n",
        "\n",
        "maes.plot()\n",
        "plt.title(\"Performances (MAE) pour différents nombres de variables prédictives\")\n",
        "plt.xlabel(\"Nombre de variables prédictives\")\n",
        "plt.ylabel(\"Maen Absolute Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0xYzhPQ1lRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maes['val'].min(), maes['val'].idxmin()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b-C0Mb14Hzo",
        "colab_type": "text"
      },
      "source": [
        "* On peut constater que les 10-12 variables prédictives les moins corrélées à SalePrice sont (logiquement) assez inefficaces pour prédire le prix.\n",
        "* Les meilleurs résultats en validation sont obtenus avec les 25-30 variables les plus corrélées au prix. (cela peut varier selon la sélection du set d'entraînement)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dswF-30GVnAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Meilleur résultat en validation\n",
        "featurelist = best_features[:28]\n",
        "\n",
        "X = ames[featurelist]\n",
        "y = ames[\"SalePrice\"]\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "\n",
        "price_predictor.fit(Xtrain, ytrain)\n",
        "trainpred = price_predictor.predict(Xtrain)\n",
        "valpred = price_predictor.predict(Xval)\n",
        "\n",
        "def display_results(labels, predictions, title = \"Model results\", figsize = (10,6), **kwargs):\n",
        "  \n",
        "  print(\"Mean average error: \", MAE(labels, predictions))  \n",
        "  plt.scatter(labels, predictions, s=2, label = title, **kwargs)\n",
        "  plt.gcf().set_size_inches(figsize)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"Labels\")\n",
        "  plt.ylabel(\"Prédictions\")\n",
        "  prev_legend = plt.legend()\n",
        "  plt.legend()\n",
        "  xmin, xmax = plt.gca().get_xlim()\n",
        "  plt.plot([xmin,xmax],[xmin,xmax], 'k')\n",
        "\n",
        "print(MAE(ytrain, trainpred), MAE(yval, valpred))\n",
        "\n",
        "display_results(yval, valpred, \"Régression linéaire - validation set\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uugb_WZ_hh8D",
        "colab_type": "text"
      },
      "source": [
        "On constate que le nuage de doit semble former une légère courbe. Cela semble indiquer qu'il existe des relations non-linéaires, telles que des relations polynomiales entre les variables et le prix. La régression linéaire se base en effet sur l'hypothèse très simpliste que les relations seraient linéaires. Si on revisualise les nuages de points plus haut montrant l'interactions entre différentes variables (comme 'OverallQual') et le prix, on constate que la relation et plutôt quadratique que linéaire.\n",
        "\n",
        "Une variation de la régression linéaire, appelée régression polynomiale, permet de facilement prendre en compte de potentielles interactions non-linéaires entre les variables, en créant de nouvelles variables à partir de polynômes des variables d'origine. Bien sûr, les possibilités ne se liminent pas aux polynômes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAI-or-klHpt",
        "colab_type": "text"
      },
      "source": [
        "##Régression polynomiale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgiED5-Ug39a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_polynomials(X):\n",
        "  #(remove some unwanted warnings)\n",
        "  prev = pd.options.mode.chained_assignment\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  for col in X.columns:\n",
        "    #prise en compte des carrés des variables\n",
        "    X[col+\"_square\"] = X[col]**2\n",
        "    #prise en compte des racines carrées\n",
        "    X[col+\"_sqrt\"] = X[col]**(1/2)\n",
        "  \n",
        "  pd.options.mode.chained_assignment = prev\n",
        "  \n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cp45O_3hEqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featurelist = best_features[:28]\n",
        "\n",
        "X = ames[featurelist]\n",
        "X = add_polynomials(X)\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "price_predictor.fit(Xtrain, ytrain)\n",
        "trainpred, valpred = price_predictor.predict(Xtrain), price_predictor.predict(Xval)\n",
        "\n",
        "print(\"MAE (train,val):\", MAE(trainpred, ytrain), MAE(valpred, yval))\n",
        "display_results(yval, valpred, \"Régression polynomiale (sqrt et square) - validation set\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO_nP6e-ru99",
        "colab_type": "text"
      },
      "source": [
        "Les prédiction semblent suivre une ligne droite. On remarque par contre que certaines prédictions parfois sont très mauvaises, et parfois même négatives (et peuvent aller jusqu'à -5.000.000 selon l'état pseudo-aléatoire utilisé).\n",
        "\n",
        "Un simple bornage des prédictions entre les prix minimum et maximum du set d'entraînement permet de limiter ces erreurs exceptionnelles.\n",
        "\n",
        "Néanmoins, selon les objectifs, il convient de définir une métrique d'évaluation appropriée: si quelques rares erreurs très grandes sont tolérables, ou si il est préférable d'avoir des prédictions globalement un peu moins précises mais sans gros écarts.\n",
        "Dans tous les cas, on peut facilement améliorer les résultats en contraignant les prédictions entre des valeurs limites."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKU4XFodjXLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lowest_pred_index = yval.index[valpred.argmin()]\n",
        "display_series(ames.loc[lowest_pred_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt96KbO9sFfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainpred = trainpred.clip(ytrain.min(), ytrain.max())\n",
        "valpred = valpred.clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "print(\"MAE (train,val):\", MAE(trainpred, ytrain), MAE(valpred, yval))\n",
        "display_results(yval, valpred, \"Régression polynomiale (sqrt et square) corrigée - validation set\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZoJLuVkVIRx",
        "colab_type": "text"
      },
      "source": [
        "## Comparaison pour différents nombres d'exemples (taille du training set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74RICIET8YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maes2 = pd.DataFrame(columns = ['train','val']) \n",
        "\n",
        "plot_limit = 0\n",
        "leg = []\n",
        "\n",
        "for nsamples in range(10,800,10):\n",
        "  \n",
        "  \n",
        "  trainset, valset = train_test_split(ames, test_size = 660, random_state=1)\n",
        "  \n",
        "  #On extrait un sample sur le training set\n",
        "  trainset_sample = trainset.sample(nsamples, random_state=1)\n",
        "  \n",
        "  Xtrain = trainset_sample[featurelist]\n",
        "  ytrain = trainset_sample[\"SalePrice\"]\n",
        "  \n",
        "  Xval = valset[featurelist]\n",
        "  yval = valset[\"SalePrice\"]\n",
        "  \n",
        "  price_predictor.fit(Xtrain, ytrain)\n",
        "  \n",
        "  trainpred = price_predictor.predict(Xtrain)\n",
        "  valpred = price_predictor.predict(Xval)  \n",
        "  trainpred = trainpred.clip(ytrain.min(), ytrain.max())\n",
        "  valpred = valpred.clip(ytrain.min(), ytrain.max())  \n",
        "  maes2.loc[nsamples] = MAE(ytrain, trainpred), MAE(yval, valpred)\n",
        "  if nsamples in [10,50,100,790]:    \n",
        "    display_results(yval, valpred, \"Résultats pour nsamples = \" + str(nsamples))\n",
        "\n",
        "maes2.plot()\n",
        "plt.title(\"Performances (MAE) pour différentes tailles de set d'entraînement\")\n",
        "plt.xlabel(\"Nombre d'observations d'entraînement\")\n",
        "plt.ylabel(\"Mean Absolute Error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atnp5Lo6aaLe",
        "colab_type": "text"
      },
      "source": [
        "On constate que les performances diminuent (l'erreur augmente) avec le nombre d'échantillons d'entraînement, et que les performances en validation sont au départ beaucoup plus faibles, ce qui est signe d'**overfitting**. En effet, en utilisant seulement 50 exemples (gauche du graphe), on remarque que le modèle compte presque autant de paramètres (un par variable prédictive). Dans ce cas, les paramètres peuvent être adaptés aux exemples spécifiques d'entraînement pour apprendre leur prédiction presque \"par coeur\". Le modèle n'est alors pas générique et fonctionne mal sur de nouvelles données (comme le montrent les faibles performances en validation). On constate ensuite que pour 400 échantillons d'entraînement, les performances en entraînement se stabilisent, et les performances en validation sont équivalentes, ce qui signifie que le nombre d'échantillons est suffisant (plus d'overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6tK_SqBZZY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(price_predictor.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL63VJR3c7fu",
        "colab_type": "text"
      },
      "source": [
        "## Performances réelles\n",
        "\n",
        "Pour évaluer les performances réelles du modèles, nous devons utiliser un set de données qui n'a pas encore été utilisé, ni pour l'entraînement ni pour la validation. Cela permet de simuler une utilisation réelle du modèle, sur de nouvelles maisons (dont on voudrait estimer le prix). L'évaluation des performances à partir du set de validation seraient biaisée, car il a en effet permis de choisir les paramètres du modèles, en l'occurence le choix des variables prédictives (le modèle a donc été indirectement optimisé pour ces données spécifiques).\n",
        "\n",
        "Sur la plateforme [Kaggle](https://www.kaggle.com/), pour garantir l'absence de biais lors du design du modèle, un set de test est généralement fourni séparément, et les labels ne sont volontairement pas fournis. L'utilisateur de la plateforme doit alors soumettre à la plateforme les prédictions données par le modèle développé, et reçoit le résultat de l'évaluation effectuée par la plateforme. Cela permet notamment de classer différents compétiteurs lors d'un concours: https://www.kaggle.com/competitions\n",
        "\n",
        "Concernant le dataset utilisé, on peut soumettre des prédictions ici: https://www.kaggle.com/c/home-data-for-ml-course/overview/evaluation\n",
        "\n",
        "Remarque: lorsque le concours ne sera fini, il sera toujours possible de récupérer les données complète ici: https://www.kaggle.com/prevek18/ames-housing-dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5eYYBMhTQJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vérifions déjà les performances sur le set de validation\n",
        "#Régression linéaire\n",
        "\n",
        "X = ames[featurelist]\n",
        "y = ames[\"SalePrice\"]\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "\n",
        "price_predictor.fit(Xtrain, ytrain)\n",
        "\n",
        "trainpreds = price_predictor.predict(Xtrain).clip(ytrain.min(), ytrain.max())\n",
        "valpreds_lin = price_predictor.predict(Xval).clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "MAE(trainpreds,ytrain.values), MAE(valpreds_lin,yval.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_tHgbL2p_mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Régression polynomiale\n",
        "X = ames[featurelist]\n",
        "X = add_polynomials(X)\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]\n",
        "\n",
        "poly_predictor = LinearRegression()\n",
        "poly_predictor.fit(Xtrain, ytrain)\n",
        "\n",
        "trainpreds = poly_predictor.predict(Xtrain).clip(ytrain.min(), ytrain.max())\n",
        "valpreds_poly = poly_predictor.predict(Xval).clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "MAE(trainpreds,ytrain.values), MAE(valpreds_poly,yval.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xDnxJVEhBI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_results(yval.values, valpreds_lin, \"Régression linéaire\")\n",
        "display_results(yval.values, valpreds_poly, \"Régression polynomiale\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2chtMCm7-T7k",
        "colab_type": "text"
      },
      "source": [
        "Remarquez que vous obtiendrez des résultats différents à chaque fois que vous relancez les cellules ci-dessus avec un random_state différent: cela est dû à la séparation aléatoire des sets d'entraînement et de validation. \n",
        "\n",
        "Afin d'avoir un indicateur plus robuste du modèle, une possibilité serait de calculer une moyenne de ces résultats, ou d'utiliser un processus de **k-fold cross-validation**: on découpe l'ensemble des données en k échantillons, et pour chaque échantillon on entraînement un modèle sur les autres données, et on calcule les prédictions pour l'échantillon gardé de côté. On calcule de cette manière des prédictions pour chaque échantillon et on extrait une mesure (e.g., MAE) sur l'ensemble des prédictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW14_M7l0N5X",
        "colab_type": "text"
      },
      "source": [
        "### Vérification du set de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM8eeCvzzsLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/titsitits/Python_Data_Science/master/Donn%C3%A9es/test.csv\")\n",
        "\n",
        "ids = testset['Id']\n",
        "\n",
        "print(len(testset))\n",
        "\n",
        "#nettoyage du testset\n",
        "testset = clean_df(testset)\n",
        "\n",
        "#Colonnes incomplètes\n",
        "counts = testset.count()\n",
        "incomplete = counts[counts < len(testset)]\n",
        "display_series(incomplete.sort_values())\n",
        "len(incomplete.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1KVfZDT4hkF",
        "colab_type": "text"
      },
      "source": [
        "Il reste deux observations contenant des variables invalides. On va simplement remplacer les valeurs manquantes par les moyennes. Si le nombre d'observations à nettoyer était plus conséquent, il serait pertinent d'analyser les variables à corriger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BVOHMFc_H0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in incomplete.index:\n",
        "  testset[col] = testset[col].fillna(ames[col].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ai3HrFnNLmt",
        "colab_type": "text"
      },
      "source": [
        "### Soumission des résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSvjBcA7bEi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = ames[featurelist]\n",
        "y = ames[\"SalePrice\"]\n",
        "#On peut ré-entraîner le modèle sur tout le dataset (entraînement+validation), pour le rendre potentiellement plus robuste\n",
        "price_predictor.fit(X, y)\n",
        "\n",
        "#select features\n",
        "Xtest = testset[featurelist]\n",
        "\n",
        "testpreds_lin = price_predictor.predict(Xtest).clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "submission = ids.to_frame()\n",
        "submission[\"SalePrice\"] = testpreds_lin\n",
        "submission.to_csv(\"mysubmission_linear_regression.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkM2iUzEpspz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest2 = add_polynomials(Xtest)\n",
        "\n",
        "X = ames[featurelist]\n",
        "X = add_polynomials(X)\n",
        "poly_predictor.fit(X, y)\n",
        "\n",
        "testpreds_poly = poly_predictor.predict(Xtest2).clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "submission = ids.to_frame()\n",
        "submission[\"SalePrice\"] = testpreds_poly\n",
        "submission.to_csv(\"mysubmission_polynomial_regression.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23u9i5kTpKME",
        "colab_type": "text"
      },
      "source": [
        "## Exploration de base des variables catégorielles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMD_aKxojyyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Analysons l'effet de chaque variable catégorielle\n",
        "\n",
        "all_columns = ames.columns\n",
        "cat_columns = ames.columns[ames.dtypes == 'object']\n",
        "\n",
        "diffs_per_group = []\n",
        "\n",
        "#Bonus: vous pouvez afficher des graphes pour chaque groupe\n",
        "#ncols = 8\n",
        "#ncats = len(cat_columns)\n",
        "#fig, axes = plt.subplots(int(np.ceil(ncats/ncols)),ncols, figsize = (20,30))\n",
        "\n",
        "i=0\n",
        "for cat in cat_columns:  \n",
        "  \n",
        "  group_means = ames.groupby(cat)[\"SalePrice\"].mean()\n",
        "  diffs_per_group.append(group_means.max() - group_means.min())\n",
        "  \n",
        "  #Bonus: vous pouvez afficher des graphes pour chaque groupe\n",
        "  #plt.figure(figsize=(10,3))\n",
        "  #group_means.plot.bar()\n",
        "  #ax = axes[int(i/ncols), int(i%ncols)]\n",
        "  #ames.boxplot(\"SalePrice\", by=cat, ax = ax)\n",
        "  i=i+1\n",
        "\n",
        "best_cats = pd.Series(diffs_per_group, list(cat_columns)).abs().sort_values(ascending = False)\n",
        "best_cats.plot.bar(figsize=(10,4))\n",
        "\n",
        "best_cats = best_cats.index.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIoTezR8R3kr",
        "colab_type": "text"
      },
      "source": [
        "## Bonus - Un algorithme plus moderne: catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdEdNo8uPa7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installer un nouveau package: on appelle une ligne de commande linux grâce au symbole \"!\". On utilise le gestionnaire de packages python pip pour installer un nouveau package\n",
        "!pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDhe159xjnZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contfeatures = best_features[:28]\n",
        "catfeatures = best_cats[:-5] #on retire les plus mauvaises\n",
        "\n",
        "newfeaturelist =  contfeatures + catfeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuMmjKHDQYqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = ames[newfeaturelist]\n",
        "y = ames[\"SalePrice\"]\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = X.loc[trainids], X.loc[valids], y.loc[trainids], y.loc[valids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oM1lPqJiVF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from catboost import Pool, CatBoostRegressor\n",
        "\n",
        "\n",
        "cat_feature_ids = [i for i in range(len(newfeaturelist)) if newfeaturelist[i] in catfeatures]\n",
        "\n",
        "\n",
        "train_pool = Pool(Xtrain.values, ytrain.values, cat_features=cat_feature_ids)\n",
        "val_pool = Pool(Xval, yval, cat_features=cat_feature_ids) \n",
        "all_pool = Pool(X, y, cat_features=cat_feature_ids) \n",
        "\n",
        "# Spécification des paramètres d'entraînement du modèle\n",
        "model = CatBoostRegressor(iterations=300, \n",
        "                          depth=3, \n",
        "                          learning_rate=0.2, \n",
        "                          loss_function='RMSE')\n",
        "#Entraînement du modèle\n",
        "model.fit(train_pool, silent=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac894-uU00ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Réalisation de la prédiction en utilisant le modèle obtenu\n",
        "trainpreds = model.predict(train_pool)\n",
        "valpreds = model.predict(val_pool)\n",
        "\n",
        "MAE(trainpreds,ytrain.values), MAE(valpreds,yval.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pS2SzLIXCmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spécification des paramètres d'entraînement du modèle\n",
        "model = CatBoostRegressor(iterations=300, \n",
        "                          depth=3, \n",
        "                          learning_rate=0.2, \n",
        "                          loss_function='RMSE')\n",
        "\n",
        "#Entraînement du modèle, avec un critère d'arrêt lorsque les performances en validation baissent: éviter le surentraînement (overfitting)\n",
        "model.fit(train_pool,eval_set = val_pool, early_stopping_rounds = 100, silent = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOJRK7daRgy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Réalisation de la prédiction en utilisant le modèle obtenu\n",
        "trainpreds = model.predict(train_pool)\n",
        "valpreds_catboost = model.predict(val_pool)\n",
        "\n",
        "#Pour éviter de prédire des valeurs anormales, on limite les prédictions au range du set d'entraînement\n",
        "trainpreds = trainpreds.clip(ytrain.min(), ytrain.max())\n",
        "valpreds = valpreds.clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "MAE(trainpreds,ytrain.values), MAE(valpreds_catboost,yval.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4WuCGsNmTcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_results(yval.values, valpreds_lin, \"Régression linéaire\")\n",
        "display_results(yval.values, valpreds_poly, \"Régression polynomiale\")\n",
        "display_results(yval.values, valpreds_catboost, \"CatBoost\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IryInRS1ZZna",
        "colab_type": "text"
      },
      "source": [
        "### Soumission des résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlG-EhJ8ZM77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtest = testset[newfeaturelist]\n",
        "test_pool = Pool(Xtest.values, cat_features=cat_feature_ids)\n",
        "\n",
        "#Pour la soumission, on peut éventuellement réentraîner le modèle sur toutes les données d'entraînement et de validation (pour espérer avoir un modèle plus générique. Cependant: attention à l'overfitting sans critère d'arrêt)\n",
        "model.fit(all_pool, silent = True)\n",
        "\n",
        "#Prédictions\n",
        "testpreds_catboost = model.predict(test_pool).clip(ytrain.min(), ytrain.max())\n",
        "\n",
        "submission = ids.to_frame()\n",
        "submission[\"SalePrice\"] = testpreds_catboost\n",
        "submission.to_csv(\"mysubmission_catboost.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoJxO1wcUh4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pour s'assurer de la plausibilité des résultats, on peut comparer leur distribution avec ceux du dataset d'entraînement\n",
        "plt.subplot(1,2,1)\n",
        "submission.SalePrice.hist()\n",
        "plt.subplot(1,2,2)\n",
        "ames.SalePrice.hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMqBzDv9gMzb",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Les résultats avec le fichier de baseline (sample_submission.csv) ont été obtenus avec une régression linéaire sur l'année et le mosi de vente, la surface du lot et le nombre de chambres. Les résultats de la soumission sur Kaggle donnent: \n",
        "\n",
        "`MAE = 59346`\n",
        "\n",
        "Les trois soumissions proposées donnent:\n",
        "\n",
        "* régression linéaire: 20391\n",
        "* régression polynomiale: 19669\n",
        "* catboost: 14465\n",
        "\n",
        "Les algotihmes proposés prédisent donc bien mieux mieux les prix des maisons que la baseline.\n",
        "\n",
        "Le résultat obtenu avec catboost amène à la place 544/13783 au classement de la compétition Kaggle. Il reste donc de la marge de manoeuvre pour améliorer le modèle. (Le meilleur score publique est actuellement à 11824).\n",
        "\n",
        "Il existe de très nombreuses possibilités pour améliorer le modèle, dont par exemple:\n",
        "\n",
        "* Vérifier plus profondément les données et supprimer d'éventuelles anomalies\n",
        "* Tester d'autres ensembles de variables (en explorant plus profondément leurs relations et leur influence sur le prix)\n",
        "* Créer de nouvelles variables pertinentes. Par exemple, à partir de la variable catégorielle \"neighboorhood\" et du prix moyen de chaque quartier, il est possible d'extraire une variable numérique indiquant le \"standing\" du quartier. Les nombreuses variables indiquant une échelle de qualité (\"Excellent\",\"Typical\",\"Fair\", ...) peuvent être traduites en variables numériques. Des variables \"dummy\" peuvent être extraites sur d'autres catégories. Il pourrait également être intéressant de considérer [année de construction du garage] - [année de construction de la maison], par exemple pour détecter les garages \"intégrés\" (plus jolis que les ajouts postérieurs?) ou, au contraire, les travaux de re-valuation récents. Des variables simplifiées peuvent être utilisées: indiquer simplement la présence ou non d'une piscine ?\n",
        "* Les variables sont peut-être redondantes (elles apportent la même information), ce qui complexifie inutilement le modèle. Il peut être intéressant d'extraire un ensemble de variables apportant un maximum d'informations non-redondantes. E.g.: GarageArea et GarageCars apportent presque la même information.\n",
        "* Optimiser les hyperparamètres des modèles utilisés grâce à une k-fold cross-validation (régularisation de la régression linéaire, paramètres d'apprentissage d'autres algorithmes; e.g. nombre et profondeur des arbres pour CatBoost, nombre d'itération et taux d'apprentissage)\n",
        "* Tester d'autres algorithmes de machine learning (e.g.: support vector regression).\n",
        "* Entraîner plusieurs modèles, et calculer une moyenne pondérée des prédictions (on parle de model blending, ou de ensemble learning)\n",
        "\n",
        "Kaggle est une excellente source d'inspiration pour s'améliorer. On y trouve en effet de très nombreux notebooks (généralement en Python) proposant des idées intéressantes de feature engineering et de développement de modèles prédictifs. Par exemple, le notebook suivant est classé 26ème:\n",
        "https://www.kaggle.com/itslek/stack-blend-lrs-xgb-lgb-house-prices-k-v17\n",
        "La méthode propose certaines nouvelles variables prédictives simplifiées, ainsi que la moyenne pondérée de différents modèles prédictifs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zGX_8fbgPar",
        "colab_type": "text"
      },
      "source": [
        "## Bonus - Un exemple basique de model blending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_C7oDL4XJbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1, w2, w3 = 0.02, 0.08, 0.9\n",
        "valpreds_blend = w1*valpreds_lin + w2*valpreds_poly + w3*valpreds_catboost\n",
        "MAE(yval, valpreds_blend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXQrS9F3dLx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testpreds_blend = w1*testpreds_lin + w2*testpreds_poly + w3*testpreds_catboost\n",
        "submission = ids.to_frame()\n",
        "submission[\"SalePrice\"] = testpreds_blend\n",
        "submission.to_csv(\"mysubmission_blend.csv\", index = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUt50aQatG6",
        "colab_type": "text"
      },
      "source": [
        "* model blending:  `MAE = 14273`\n",
        "Nouveau classement: 516/13783"
      ]
    }
  ]
}